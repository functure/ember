{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ember'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-357e8a37bec5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0member\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maltair\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0malt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ember'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ember\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.metrics import roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/stash/dataset/ember/ember_data/\" # change this to where you unzipped https://pubdata.endgame.com/ember/ember_dataset.tar.bz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ember.create_vectorized_features(data_dir)\n",
    "_ = ember.create_metadata(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emberdf = ember.read_metadata(data_dir)\n",
    "X_train, y_train, X_test, y_test = ember.read_vectorized_features(data_dir)\n",
    "lgbm_model = lgb.Booster(model_file=os.path.join(data_dir, \"ember_model_2017.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotdf = emberdf.copy()\n",
    "gbdf = plotdf.groupby([\"label\", \"subset\"]).count().reset_index()\n",
    "alt.Chart(gbdf).mark_bar().encode(\n",
    "    alt.X('subset:O', axis=alt.Axis(title='Subset')),\n",
    "    alt.Y('sum(sha256):Q', axis=alt.Axis(title='Number of samples')),\n",
    "    alt.Color('label:N', scale=alt.Scale(range=[\"#00b300\", \"#3333ff\", \"#ff3333\"]), legend=alt.Legend(values=[\"unlabeled\", \"benign\", \"malicious\"]))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotdf = emberdf.copy()\n",
    "plotdf.loc[plotdf[\"appeared\"] < \"2017-01\", \"appeared\"] = \" <2017\"\n",
    "gbdf = plotdf.groupby([\"appeared\", \"label\"]).count().reset_index()\n",
    "alt.Chart(gbdf).mark_bar().encode(\n",
    "    alt.X('appeared:O', axis=alt.Axis(title='Month appeared')),\n",
    "    alt.Y('sum(sha256):Q', axis=alt.Axis(title='Number of samples')),\n",
    "    alt.Color('label:N', scale=alt.Scale(range=[\"#00b300\", \"#3333ff\", \"#ff3333\"]), legend=alt.Legend(values=[\"unlabeled\", \"benign\", \"malicious\"]))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = lgbm_model.predict(X_test)\n",
    "y_train_pred = lgbm_model.predict(X_train)\n",
    "emberdf[\"y_pred\"] = np.hstack((y_train_pred, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fpr(y_true, y_pred):\n",
    "    nbenign = (y_true == 0).sum()\n",
    "    nfalse = (y_pred[y_true == 0] == 1).sum()\n",
    "    return nfalse / float(nbenign)\n",
    "\n",
    "\n",
    "def find_threshold(y_true, y_pred, fpr_target):\n",
    "    thresh = 0.0\n",
    "    fpr = get_fpr(y_true, y_pred > thresh)\n",
    "    while fpr > fpr_target and thresh < 1.0:\n",
    "        thresh += 0.001\n",
    "        fpr = get_fpr(y_true, y_pred > thresh)\n",
    "    return thresh, fpr\n",
    "\n",
    "testdf = emberdf[emberdf[\"subset\"] == \"test\"]\n",
    "print(\"ROC AUC:\", roc_auc_score(testdf.label, testdf.y_pred))\n",
    "print()\n",
    "\n",
    "threshold, fpr = find_threshold(testdf.label, testdf.y_pred, 0.01)\n",
    "fnr = (testdf.y_pred[testdf.label == 1] < threshold).sum() / float((testdf.label == 1).sum())\n",
    "print(\"Ember Model Performance at 1% FPR:\")\n",
    "print(\"Threshold: {:.3f}\".format(threshold))\n",
    "print(\"False Positive Rate: {:.3f}%\".format(fpr * 100))\n",
    "print(\"False Negative Rate: {:.3f}%\".format(fnr * 100))\n",
    "print(\"Detection Rate: {}%\".format(100 - fnr * 100))\n",
    "print()\n",
    "\n",
    "threshold, fpr = find_threshold(testdf.label, testdf.y_pred, 0.001)\n",
    "fnr = (testdf.y_pred[testdf.label == 1] < threshold).sum() / float((testdf.label == 1).sum())\n",
    "print(\"Ember Model Performance at 0.1% FPR:\")\n",
    "print(\"Threshold: {:.3f}\".format(threshold))\n",
    "print(\"False Positive Rate: {:.3f}%\".format(fpr * 100))\n",
    "print(\"False Negative Rate: {:.3f}%\".format(fnr * 100))\n",
    "print(\"Detection Rate: {}%\".format(100 - fnr * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "fpr_plot, tpr_plot, _ = roc_curve(testdf.label, testdf.y_pred)\n",
    "plt.plot(fpr_plot, tpr_plot, lw=4, color='k')\n",
    "plt.gca().set_xscale(\"log\")\n",
    "plt.yticks(np.arange(22) / 20.0)\n",
    "plt.xlim([4e-5, 1.0])\n",
    "plt.ylim([0.65, 1.01])\n",
    "plt.gca().grid(True)\n",
    "plt.vlines(fpr, 0, 1 - fnr, color=\"r\", lw=2)\n",
    "plt.hlines(1 - fnr, 0, fpr, color=\"r\", lw=2)\n",
    "plt.xlabel(\"False positive rate\")\n",
    "plt.ylabel(\"True positive rate\")\n",
    "_ = plt.title(\"Ember Model ROC Curve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 8))\n",
    "testdf[testdf[\"label\"] == 0].y_pred.hist(range=[0, 1], bins=10, color=\"#3333ff\", alpha=0.8, label=\"benign\")\n",
    "testdf[testdf[\"label\"] == 1].y_pred.hist(range=[0, 1], bins=10, color=\"#ff3333\", alpha=0.8, label=\"malicious\")\n",
    "plt.gca().set_yscale(\"log\", nonposy=\"clip\")\n",
    "plt.gca().grid(False)\n",
    "plt.xlabel(\"Score\")\n",
    "plt.ylabel(\"Count\")\n",
    "_ = plt.title(\"Ember Test Set Model Score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ember.create_vectorized_features_vboat(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emberdf = ember.read_metadata(data_dir)\n",
    "X_train, y_train, X_test, y_test = ember.read_vectorized_features(data_dir)\n",
    "lgbm_model = lgb.Booster(model_file=os.path.join(data_dir, \"model_vboat.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = lgbm_model.predict(X_test)\n",
    "y_train_pred = lgbm_model.predict(X_train)\n",
    "emberdf[\"y_pred\"] = np.hstack((y_train_pred, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fpr(y_true, y_pred):\n",
    "    nbenign = (y_true == 0).sum()\n",
    "    nfalse = (y_pred[y_true == 0] == 1).sum()\n",
    "    return nfalse / float(nbenign)\n",
    "\n",
    "\n",
    "def find_threshold(y_true, y_pred, fpr_target):\n",
    "    thresh = 0.0\n",
    "    fpr = get_fpr(y_true, y_pred > thresh)\n",
    "    while fpr > fpr_target and thresh < 1.0:\n",
    "        thresh += 0.001\n",
    "        fpr = get_fpr(y_true, y_pred > thresh)\n",
    "    return thresh, fpr\n",
    "\n",
    "testdf = emberdf[emberdf[\"subset\"] == \"test\"]\n",
    "print(\"ROC AUC:\", roc_auc_score(testdf.label, testdf.y_pred))\n",
    "print()\n",
    "\n",
    "threshold, fpr = find_threshold(testdf.label, testdf.y_pred, 0.01)\n",
    "fnr = (testdf.y_pred[testdf.label == 1] < threshold).sum() / float((testdf.label == 1).sum())\n",
    "print(\"Ember Model Performance at 1% FPR:\")\n",
    "print(\"Threshold: {:.3f}\".format(threshold))\n",
    "print(\"False Positive Rate: {:.3f}%\".format(fpr * 100))\n",
    "print(\"False Negative Rate: {:.3f}%\".format(fnr * 100))\n",
    "print(\"Detection Rate: {}%\".format(100 - fnr * 100))\n",
    "print()\n",
    "\n",
    "threshold, fpr = find_threshold(testdf.label, testdf.y_pred, 0.001)\n",
    "fnr = (testdf.y_pred[testdf.label == 1] < threshold).sum() / float((testdf.label == 1).sum())\n",
    "print(\"Ember Model Performance at 0.1% FPR:\")\n",
    "print(\"Threshold: {:.3f}\".format(threshold))\n",
    "print(\"False Positive Rate: {:.3f}%\".format(fpr * 100))\n",
    "print(\"False Negative Rate: {:.3f}%\".format(fnr * 100))\n",
    "print(\"Detection Rate: {}%\".format(100 - fnr * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "fpr_plot, tpr_plot, _ = roc_curve(testdf.label, testdf.y_pred)\n",
    "plt.plot(fpr_plot, tpr_plot, lw=4, color='k')\n",
    "plt.gca().set_xscale(\"log\")\n",
    "plt.yticks(np.arange(22) / 20.0)\n",
    "plt.xlim([4e-5, 1.0])\n",
    "plt.ylim([0.65, 1.01])\n",
    "plt.gca().grid(True)\n",
    "plt.vlines(fpr, 0, 1 - fnr, color=\"r\", lw=2)\n",
    "plt.hlines(1 - fnr, 0, fpr, color=\"r\", lw=2)\n",
    "plt.xlabel(\"False positive rate\")\n",
    "plt.ylabel(\"True positive rate\")\n",
    "_ = plt.title(\"Ember Model ROC Curve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 8))\n",
    "testdf[testdf[\"label\"] == 0].y_pred.hist(range=[0, 1], bins=10, color=\"#3333ff\", alpha=0.8, label=\"benign\")\n",
    "testdf[testdf[\"label\"] == 1].y_pred.hist(range=[0, 1], bins=10, color=\"#ff3333\", alpha=0.8, label=\"malicious\")\n",
    "plt.gca().set_yscale(\"log\", nonposy=\"clip\")\n",
    "plt.gca().grid(False)\n",
    "plt.xlabel(\"Score\")\n",
    "plt.ylabel(\"Count\")\n",
    "_ = plt.title(\"Ember Test Set Model Score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
